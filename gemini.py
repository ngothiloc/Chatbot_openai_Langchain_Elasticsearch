import streamlit as st
import os
import tempfile
import asyncio
from datetime import datetime
import pytz
from dotenv import load_dotenv
from elasticsearch import Elasticsearch
from langchain_google_genai.chat_models import ChatGoogleGenerativeAI
from langchain_community.document_loaders import (
    TextLoader,
    PyPDFLoader,
    UnstructuredMarkdownLoader
)
from langchain_community.document_loaders.unstructured import UnstructuredFileLoader

# -------------------- C·∫•u h√¨nh --------------------
load_dotenv(dotenv_path=".env", override=True)
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    raise ValueError("GOOGLE_API_KEY kh√¥ng ƒë∆∞·ª£c t√¨m th·∫•y trong bi·∫øn m√¥i tr∆∞·ªùng.")

try:
    asyncio.get_running_loop()
except RuntimeError:
    asyncio.set_event_loop(asyncio.new_event_loop())

# -------------------- Elasticsearch --------------------
es = Elasticsearch("http://localhost:9200")
INDEX_NAME = "chatbot"

# T·∫°o index n·∫øu ch∆∞a c√≥
if not es.indices.exists(index=INDEX_NAME):
    es.indices.create(
        index=INDEX_NAME,
        body={
            "mappings": {
                "properties": {
                    "content": {"type": "text"}
                }
            }
        }
    )

# -------------------- Kh·ªüi t·∫°o LLM --------------------
llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash",
    model_kwargs={"async_client": False},
    google_api_key=GOOGLE_API_KEY
)

# -------------------- Streamlit UI --------------------
st.title("ü§ñ Chatbot AI v·ªõi Gemini & Elasticsearch")
st.sidebar.title("üìÇ T·∫£i l√™n t√†i li·ªáu")

uploaded_files = st.sidebar.file_uploader(
    "Ch·ªçn file ƒë·ªÉ t·∫£i l√™n",
    type=['txt', 'pdf', 'docx', 'md'],
    accept_multiple_files=True
)

# -------------------- X·ª≠ l√Ω upload file --------------------
if uploaded_files:
    for uploaded_file in uploaded_files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name

        try:
            # Load document
            if uploaded_file.name.endswith('.txt'):
                loader = TextLoader(tmp_file_path)
            elif uploaded_file.name.endswith('.pdf'):
                loader = PyPDFLoader(tmp_file_path)
            elif uploaded_file.name.endswith('.docx'):
                loader = UnstructuredFileLoader(tmp_file_path)
            elif uploaded_file.name.endswith('.md'):
                loader = UnstructuredMarkdownLoader(tmp_file_path)

            documents = loader.load()
            for doc in documents:
                content = getattr(doc, "page_content", str(doc))
                es.index(index=INDEX_NAME, document={"content": content})

            st.sidebar.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω file: {uploaded_file.name} v√† l∆∞u v√†o Elasticsearch")
        except Exception as e:
            st.sidebar.error(f"‚ùå L·ªói khi x·ª≠ l√Ω file {uploaded_file.name}: {str(e)}")
        finally:
            os.unlink(tmp_file_path)

# -------------------- Hi·ªÉn th·ªã document ƒë√£ l∆∞u --------------------
st.sidebar.subheader("üìë Danh s√°ch document ƒë√£ l∆∞u trong Elasticsearch")
if st.sidebar.button("C·∫≠p nh·∫≠t danh s√°ch"):
    try:
        res = es.search(index=INDEX_NAME, query={"match_all": {}}, size=1000)
        docs = [hit["_source"]["content"] for hit in res["hits"]["hits"]]
        st.sidebar.write(f"üîé T·ªïng s·ªë document: {len(docs)}")
        for i, doc in enumerate(docs, 1):
            st.sidebar.write(f"{i}. {doc[:200]}{'...' if len(doc) > 200 else ''}")
    except Exception as e:
        st.sidebar.error(f"‚ùå L·ªói khi l·∫•y document: {str(e)}")

# -------------------- Chat History --------------------
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# -------------------- Chat Response --------------------
import random

greetings = [
    "Theo m√¨nh bi·∫øt th√¨...",
    "Hello üëã, theo th√¥ng tin m√¨nh bi·∫øt ƒë∆∞·ª£c...",
    "Ch√†o b·∫°n üëã, m√¨nh bi·∫øt r·∫±ng...",
    "Xin ch√†o, theo ki·∫øn th·ª©c m√¨nh c√≥ th√¨...",
    "Hi b·∫°n üòÉ, m√¨nh ƒë∆∞·ª£c bi·∫øt r·∫±ng...",
    "Theo nh·ªØng g√¨ m√¨nh bi·∫øt th√¨...",
    "Ch√†o b·∫°n, m√¨nh bi·∫øt ƒë∆∞·ª£c th√¥ng tin nh∆∞ sau...",
    "Theo hi·ªÉu bi·∫øt c·ªßa m√¨nh th√¨...",
    "Hello b·∫°n, m√¨nh c√≥ th·ªÉ chia s·∫ª r·∫±ng...",
    "Theo ki·∫øn th·ª©c m√¨nh bi·∫øt th√¨..."
]


closings = [
    "Hy v·ªçng th√¥ng tin n√†y h·ªØu √≠ch cho b·∫°n üòä",
    "Mong r·∫±ng c√¢u tr·∫£ l·ªùi ƒë√£ gi√∫p b·∫°n üëç",
    "N·∫øu c·∫ßn th√™m chi ti·∫øt, m√¨nh s·∫µn s√†ng h·ªó tr·ª£ nh√© üåü"
    "R·∫•t vui khi ƒë∆∞·ª£c h·ªó tr·ª£!"
]

greeting = random.choice(greetings)
closing = random.choice(closings)

# -------------------- Chat Input --------------------
if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    response = ""

    # Ki·ªÉm tra c√¢u h·ªèi v·ªÅ th·ªùi gian
    time_keywords = {"date": ["what day", "what date", "today", "ng√†y", "th·ª©", "date"],
                     "time": ["what time", "now", "gi·ªù", "th·ªùi gian", "time"]}
    
    prompt_lower = prompt.lower()
    is_date = any(k in prompt_lower for k in time_keywords["date"])
    is_time = any(k in prompt_lower for k in time_keywords["time"])

    if is_date or is_time:
        tz = pytz.timezone('Asia/Ho_Chi_Minh')
        now = datetime.now(tz)
        weekdays = ["Th·ª© Hai","Th·ª© Ba","Th·ª© T∆∞","Th·ª© NƒÉm","Th·ª© S√°u","Th·ª© B·∫£y","Ch·ªß Nh·∫≠t"]
        months = [None,"th√°ng 1","th√°ng 2","th√°ng 3","th√°ng 4","th√°ng 5","th√°ng 6",
                  "th√°ng 7","th√°ng 8","th√°ng 9","th√°ng 10","th√°ng 11","th√°ng 12"]

        date_str = f"{weekdays[now.weekday()]}, {now.day} {months[now.month]} nƒÉm {now.year}"
        time_str = f"{now.hour:02d}:{now.minute:02d}:{now.second:02d} {tz.zone}"

        if is_date and is_time:
            response = f"üìÖ H√¥m nay l√† {date_str} v√† ‚è∞ hi·ªán t·∫°i l√† {time_str}"
        elif is_date:
            response = f"üìÖ H√¥m nay l√† {date_str}"
        else:
            response = f"‚è∞ B√¢y gi·ªù l√† {time_str}"

    # N·∫øu kh√¥ng ph·∫£i c√¢u h·ªèi v·ªÅ th·ªùi gian, m·ªõi g·ªçi LLM + Elasticsearch
    if not response:
        try:
            query = {"query": {"match": {"content": prompt}}}
            res = es.search(index=INDEX_NAME, body=query, size=5)
            context_text = "\n\n".join(hit["_source"]["content"] for hit in res["hits"]["hits"])

            if context_text.strip():
                full_prompt = f"""
·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¢n thi·ªán, n√≥i chuy·ªán t·ª± nhi√™n v√† d·ªÖ hi·ªÉu. 
Vai tr√≤ c·ªßa b·∫°n g·ªìm:

1. Tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng d·ª±a tr√™n d·ªØ li·ªáu cung c·∫•p (∆∞u ti√™n s·ª≠ d·ª•ng d·ªØ li·ªáu n√†y khi c√≥ li√™n quan).
2. Ngo√†i d·ªØ li·ªáu cung c·∫•p, b·∫°n c≈©ng c√≥ th·ªÉ chia s·∫ª c√°c ki·∫øn th·ª©c c∆° b·∫£n v·ªÅ:
   - Cu·ªôc s·ªëng h√†ng ng√†y (v√≠ d·ª•: th·ªùi gian, th·ªùi ti·∫øt, th√≥i quen, s·ª©c kh·ªèe c∆° b·∫£n...).
   - C√°c ƒë·∫•t n∆∞·ªõc, con ng∆∞·ªùi, vƒÉn h√≥a, l·ªãch s·ª≠.
   - Vi·ªát Nam: vƒÉn h√≥a, ƒë·ªãa l√Ω, l·ªãch s·ª≠, c√°c s·ª± ki·ªán c∆° b·∫£n
   - C√°c qu·ªëc gia kh√°c: vƒÉn h√≥a, ƒë·ªãa l√Ω, l·ªãch s·ª≠, c√°c s·ª± ki·ªán c∆° b·∫£n.
   - C√°c m√¥n h·ªçc, ng√†nh ngh·ªÅ, c√¥ng vi·ªác.
   - C√°c v·∫•n ƒë·ªÅ x√£ h·ªôi, ch√≠nh tr·ªã, x√£ h·ªôi.
3. Khi kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi trong d·ªØ li·ªáu, h√£y d√πng ki·∫øn th·ª©c chung ƒë·ªÉ tr·∫£ l·ªùi thay v√¨ n√≥i "kh√¥ng bi·∫øt".

Phong c√°ch tr·∫£ l·ªùi:
- Lu√¥n c√≥ l·ªùi ch√†o ng·∫Øn g·ªçn ·ªü ƒë·∫ßu (nh∆∞ng thay ƒë·ªïi c√°ch ch√†o, v√≠ d·ª•: "Ch√†o b·∫°n üëã", "Xin ch√†o", "Hi b·∫°n üòÉ").
- N·ªôi dung tr·∫£ l·ªùi ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu, c√≥ th·ªÉ d√πng g·∫°ch ƒë·∫ßu d√≤ng.
- Lu√¥n c√≥ c√¢u k·∫øt th√∫c l·ªãch s·ª± ·ªü cu·ªëi (thay ƒë·ªïi linh ho·∫°t, v√≠ d·ª•: "Hy v·ªçng th√¥ng tin n√†y h·ªØu √≠ch üòä", "Mong r·∫±ng ƒëi·ªÅu n√†y gi√∫p √≠ch cho b·∫°n üëç").
- Sau c√¢u k·∫øt th√∫c, g·ª£i √Ω th√™m 2-3 c√¢u h·ªèi ti·∫øp theo (ƒëa d·∫°ng ki·ªÉu: "T·∫°i sao...", "L√†m th·∫ø n√†o...", "Bao l√¢u...", "·ªû ƒë√¢u...").

4 V·ªÅ ETV ‚Äì Vi·ªán Ki·ªÉm ƒë·ªãnh C√¥ng ngh·ªá v√† M√¥i tr∆∞·ªùng: 
   * L√† m·ªôt vi·ªán chuy√™n cung c·∫•p c√°c d·ªãch v·ª•: ki·ªÉm ƒë·ªãnh, hi·ªáu chu·∫©n, quan tr·∫Øc m√¥i tr∆∞·ªùng, quan tr·∫Øc ƒë·ªëi ch·ª©ng, thi·∫øt k·∫ø c∆° s·ªü d·ªØ li·ªáu v√† ph·∫ßn m·ªÅm qu·∫£n l√Ω. 
   * C√≥ ƒë·ªôi ng≈© chuy√™n gia gi√†u kinh nghi·ªám v√† nƒÉng l·ª±c trong nghi√™n c·ª©u v√† ·ª©ng d·ª•ng c√¥ng ngh·ªá m·ªõi. 
   * C√≥ h·ªì s∆° nƒÉng l·ª±c, g·ªìm: quy·∫øt ƒë·ªãnh ch·ªâ ƒë·ªãnh ki·ªÉm ƒë·ªãnh/ hi·ªáu chu·∫©n/ th·ª≠ nghi·ªám (m·ªõi nh·∫•t nƒÉm 2024), c√¥ng nh·∫≠n ISO 17025, danh m·ª•c quy tr√¨nh & ph∆∞∆°ng ti·ªán ƒëo.
   * Tr·ª• s·ªü t·∫°i Khu C3-2B/NO4, ph∆∞·ªùng Th·∫°ch B√†n, Qu·∫≠n Long Bi√™n, H√† N·ªôi, v√† c√≥ cam k·∫øt b·∫£o m·∫≠t th√¥ng tin ng∆∞·ªùi d√πng.

Khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ ETV, b·∫°n c√≥ th·ªÉ tr·∫£ l·ªùi d·ª±a tr√™n th√¥ng tin n√†y.

D·ªØ li·ªáu:
{context_text}

Y√™u c·∫ßu tr·∫£ l·ªùi:
- B·∫Øt ƒë·∫ßu c√¢u tr·∫£ l·ªùi b·∫±ng: "{greeting}"
- Tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch, c√≥ th·ªÉ d√πng g·∫°ch ƒë·∫ßu d√≤ng n·∫øu nhi·ªÅu √Ω.
- K·∫øt th√∫c b·∫±ng: "{closing}"
- Sau c√¢u k·∫øt th√∫c, h√£y g·ª£i √Ω 2-3 c√¢u h·ªèi li√™n quan m√† ng∆∞·ªùi d√πng c√≥ th·ªÉ h·ªèi ti·∫øp theo.
- Tuy·ªát ƒë·ªëi kh√¥ng l·∫∑p l·∫°i nguy√™n vƒÉn to√†n b·ªô d·ªØ li·ªáu, ch·ªâ ch·ªçn th√¥ng tin li√™n quan.

C√¢u h·ªèi: {prompt}
"""
            else:
                full_prompt = f"B·∫°n h√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn, th√¢n thi·ªán v√† d·ªÖ hi·ªÉu cho c√¢u h·ªèi: {prompt}"

            llm_response = llm.invoke(full_prompt)
            response = llm_response.content  # Ch·ªâ l·∫•y ph·∫ßn content
        except Exception as e:
            response = f"‚ö†Ô∏è T√¥i xin l·ªói, g·∫∑p l·ªói khi t√¨m ki·∫øm th√¥ng tin: {str(e)}"

    st.session_state.messages.append({"role": "assistant", "content": response})
    with st.chat_message("assistant"):
        st.markdown(response)
